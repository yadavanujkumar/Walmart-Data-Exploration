# Project Architecture and Workflow

## ğŸ“ Project Structure

```
Walmart-Data-Exploration/
â”‚
â”œâ”€â”€ ğŸ“Š DATA
â”‚   â””â”€â”€ walmart.csv                    # Raw sales data (6,435 records)
â”‚
â”œâ”€â”€ ğŸ““ ANALYSIS NOTEBOOKS
â”‚   â””â”€â”€ walmart_analysis.ipynb         # Complete EDA + ML + DL analysis
â”‚
â”œâ”€â”€ ğŸ PYTHON SCRIPTS
â”‚   â”œâ”€â”€ train_model.py                 # Quick model training script
â”‚   â””â”€â”€ predict.py                     # Prediction script
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                      # Main project documentation
â”‚   â”œâ”€â”€ QUICKSTART.md                  # 5-minute getting started guide
â”‚   â”œâ”€â”€ INSIGHTS.md                    # Detailed analysis insights
â”‚   â”œâ”€â”€ CONTRIBUTING.md                # Contribution guidelines
â”‚   â””â”€â”€ ARCHITECTURE.md                # This file
â”‚
â”œâ”€â”€ âš™ï¸ CONFIGURATION
â”‚   â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚   â””â”€â”€ .gitignore                     # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“œ LICENSE
â”‚   â””â”€â”€ LICENSE                        # MIT License
â”‚
â””â”€â”€ ğŸ¯ GENERATED OUTPUTS (after running)
    â”œâ”€â”€ Models/
    â”‚   â”œâ”€â”€ best_model.pkl             # Best traditional ML model
    â”‚   â”œâ”€â”€ best_traditional_model.pkl # Alternative saved model
    â”‚   â”œâ”€â”€ neural_network_model.h5    # Deep learning NN model
    â”‚   â”œâ”€â”€ lstm_model.h5              # LSTM time series model
    â”‚   â”œâ”€â”€ feature_scaler.pkl         # StandardScaler object
    â”‚   â””â”€â”€ scaler.pkl                 # Alternative scaler
    â”‚
    â”œâ”€â”€ Feature Info/
    â”‚   â””â”€â”€ feature_names.txt          # List of features used
    â”‚
    â””â”€â”€ Visualizations/
        â”œâ”€â”€ eda_distributions.png
        â”œâ”€â”€ correlation_matrix.png
        â”œâ”€â”€ feature_relationships.png
        â”œâ”€â”€ seasonal_patterns.png
        â”œâ”€â”€ model_comparison.png
        â”œâ”€â”€ feature_importance.png
        â”œâ”€â”€ predictions_vs_actual.png
        â”œâ”€â”€ nn_training_history.png
        â”œâ”€â”€ lstm_training_history.png
        â”œâ”€â”€ final_model_comparison.png
        â””â”€â”€ residual_analysis.png
```

---

## ğŸ”„ Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  walmart.csv    â”‚  Raw Data
â”‚  (6,435 rows)   â”‚  8 features
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DATA LOADING & VALIDATION         â”‚
â”‚   - Load CSV with pandas            â”‚
â”‚   - Check for missing values        â”‚
â”‚   - Validate data types             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FEATURE ENGINEERING               â”‚
â”‚   â”œâ”€ Temporal Features (6)          â”‚
â”‚   â”‚  â””â”€ Year, Month, Week, etc.     â”‚
â”‚   â”œâ”€ Lag Features (4)               â”‚
â”‚   â”‚  â””â”€ Previous 1-4 weeks sales    â”‚
â”‚   â”œâ”€ Rolling Stats (2)              â”‚
â”‚   â”‚  â””â”€ Mean & Std over 4 weeks     â”‚
â”‚   â””â”€ Store Statistics (2)           â”‚
â”‚      â””â”€ Store mean & std            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DATA PREPARATION                  â”‚
â”‚   - Remove NaN (from lag features)  â”‚
â”‚   - Sort chronologically            â”‚
â”‚   - Split train/test (80/20)       â”‚
â”‚   - Scale features (StandardScaler) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼          â–¼          â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ML    â”‚ â”‚  ML    â”‚ â”‚   DL    â”‚ â”‚   DL    â”‚
    â”‚ Linear â”‚ â”‚ Ensembleâ”‚ â”‚ Neural  â”‚ â”‚  LSTM   â”‚
    â”‚ Models â”‚ â”‚ Models â”‚ â”‚ Network â”‚ â”‚  Model  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚          â”‚           â”‚           â”‚
        â–¼          â–¼           â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         MODEL EVALUATION                  â”‚
    â”‚  - RÂ² Score, RMSE, MAE                   â”‚
    â”‚  - Feature Importance                     â”‚
    â”‚  - Residual Analysis                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     MODEL SELECTION & SAVING              â”‚
    â”‚  - Compare all models                     â”‚
    â”‚  - Select best performer                  â”‚
    â”‚  - Save models (.pkl, .h5)               â”‚
    â”‚  - Generate visualizations                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          PREDICTION                       â”‚
    â”‚  - Load saved model                       â”‚
    â”‚  - Prepare input features                 â”‚
    â”‚  - Scale features                         â”‚
    â”‚  - Make prediction                        â”‚
    â”‚  - Return sales forecast                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Machine Learning Pipeline

### 1. Data Preprocessing Pipeline
```
Raw Data â†’ Date Parsing â†’ Feature Extraction â†’ Lag Creation â†’ 
Rolling Stats â†’ Store Aggregation â†’ NaN Removal â†’ Train/Test Split â†’ 
Feature Scaling â†’ Ready for Modeling
```

### 2. Model Training Pipeline
```
Scaled Features â†’ Model Initialization â†’ Hyperparameter Setting â†’ 
Model Training â†’ Prediction on Train Set â†’ Prediction on Test Set â†’ 
Metric Calculation â†’ Model Comparison â†’ Best Model Selection â†’ 
Model Persistence
```

### 3. Prediction Pipeline
```
New Data â†’ Feature Engineering â†’ Feature Alignment â†’ 
Feature Scaling â†’ Model Loading â†’ Prediction â†’ Output
```

---

## ğŸ¯ Model Architecture Details

### Traditional ML Models

#### Random Forest Architecture
```
Input Features (19) 
    â†’ Bootstrap Sampling
    â†’ Decision Tree 1
    â†’ Decision Tree 2
    â†’ ...
    â†’ Decision Tree 100
    â†’ Majority Vote
    â†’ Predicted Sales
```

#### Gradient Boosting Architecture
```
Input Features (19)
    â†’ Weak Learner 1 (depth=5)
    â†’ Residual Calculation
    â†’ Weak Learner 2 (learns from residuals)
    â†’ ...
    â†’ Weak Learner 100
    â†’ Weighted Sum
    â†’ Predicted Sales
```

### Deep Learning Models

#### Neural Network Architecture
```
Input Layer (19 features)
    â†“
Dense(256) â†’ ReLU â†’ BatchNorm â†’ Dropout(0.3)
    â†“
Dense(128) â†’ ReLU â†’ BatchNorm â†’ Dropout(0.3)
    â†“
Dense(64) â†’ ReLU â†’ BatchNorm â†’ Dropout(0.2)
    â†“
Dense(32) â†’ ReLU â†’ Dropout(0.2)
    â†“
Output Layer (1) â†’ Linear
    â†“
Predicted Sales
```

**Training Configuration:**
- Optimizer: Adam (lr=0.001)
- Loss: MSE
- Callbacks: EarlyStopping, ReduceLROnPlateau
- Epochs: Up to 100 (early stopping)
- Batch Size: 64

#### LSTM Architecture
```
Input Sequences (10 timesteps Ã— 19 features)
    â†“
LSTM(128) â†’ Tanh â†’ Dropout(0.3) â†’ Return Sequences
    â†“
LSTM(64) â†’ Tanh â†’ Dropout(0.3) â†’ Return Sequences
    â†“
LSTM(32) â†’ Tanh â†’ Dropout(0.2)
    â†“
Dense(16) â†’ ReLU
    â†“
Output Layer (1) â†’ Linear
    â†“
Predicted Sales
```

**Training Configuration:**
- Optimizer: Adam (lr=0.001)
- Loss: MSE
- Sequence Length: 10 weeks
- Callbacks: EarlyStopping, ReduceLROnPlateau
- Epochs: Up to 50
- Batch Size: 64

---

## ğŸ“Š Feature Engineering Flow

```
Original Features (8):
â”œâ”€ Store
â”œâ”€ Date              â”€â”€â”€â”€â”€â”
â”œâ”€ Weekly_Sales      â”€â”€â”  â”‚
â”œâ”€ Holiday_Flag        â”‚  â”‚
â”œâ”€ Temperature         â”‚  â”‚
â”œâ”€ Fuel_Price          â”‚  â”‚
â”œâ”€ CPI                 â”‚  â”‚
â””â”€ Unemployment        â”‚  â”‚
                       â”‚  â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
     â”‚                    â”‚
     â–¼                    â–¼
Lag Features (4):    Temporal Features (6):
â”œâ”€ Sales_Lag_1       â”œâ”€ Year
â”œâ”€ Sales_Lag_2       â”œâ”€ Month
â”œâ”€ Sales_Lag_3       â”œâ”€ Week
â””â”€ Sales_Lag_4       â”œâ”€ Quarter
     â”‚               â”œâ”€ Day
     â–¼               â””â”€ DayOfWeek
Rolling Stats (2):        â”‚
â”œâ”€ Sales_Rolling_Mean_4   â”‚
â””â”€ Sales_Rolling_Std_4    â”‚
     â”‚                    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
      Store Statistics (2):
      â”œâ”€ Store_Mean_Sales
      â””â”€ Store_Std_Sales
              â”‚
              â–¼
    Final Feature Set (19)
```

---

## ğŸ”„ Training vs Prediction Workflow

### Training Workflow
```
1. Load Historical Data (walmart.csv)
2. Perform Feature Engineering
3. Split into Train/Test
4. Scale Features
5. Train Multiple Models
6. Evaluate & Compare
7. Select Best Model
8. Save Model + Scaler
9. Generate Reports
```

### Prediction Workflow
```
1. Load Saved Model + Scaler
2. Receive New Input Data
3. Apply Same Feature Engineering
4. Scale with Saved Scaler
5. Make Prediction
6. Return Forecast
```

---

## ğŸ›ï¸ Component Interactions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Interface                       â”‚
â”‚  (Jupyter Notebook / CLI Scripts)                â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â”€â”€ Data Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚    â”œâ”€ walmart.csv (storage)                â”‚
      â”‚    â””â”€ pandas DataFrame (in-memory)         â”‚
      â”‚                                             â”‚
      â”œâ”€â”€â”€ Processing Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚    â”œâ”€ Feature Engineering Module           â”‚
      â”‚    â”œâ”€ Data Validation Module               â”‚
      â”‚    â””â”€ Scaling Module (StandardScaler)      â”‚
      â”‚                                             â”‚
      â”œâ”€â”€â”€ Model Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚    â”œâ”€ Traditional ML (scikit-learn)        â”‚
      â”‚    â”‚  â”œâ”€ Linear Models                     â”‚
      â”‚    â”‚  â””â”€ Ensemble Models                   â”‚
      â”‚    â””â”€ Deep Learning (TensorFlow/Keras)     â”‚
      â”‚       â”œâ”€ Neural Network                    â”‚
      â”‚       â””â”€ LSTM                              â”‚
      â”‚                                             â”‚
      â”œâ”€â”€â”€ Evaluation Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚    â”œâ”€ Metrics Calculation                  â”‚
      â”‚    â”œâ”€ Model Comparison                     â”‚
      â”‚    â””â”€ Visualization Generation             â”‚
      â”‚                                             â”‚
      â””â”€â”€â”€ Persistence Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
           â”œâ”€ Model Serialization (.pkl, .h5)      â”‚
           â”œâ”€ Scaler Serialization                 â”‚
           â””â”€ Results Export (images, reports)     â”‚
```

---

## ğŸš€ Execution Paths

### Path 1: Complete Analysis (Jupyter Notebook)
```
Start â†’ Launch Notebook â†’ Run All Cells â†’
EDA â†’ Feature Engineering â†’ ML Training â†’
DL Training â†’ Evaluation â†’ Visualization â†’
Insights Generation â†’ Model Saving â†’ End
```
**Time**: 10-20 minutes  
**Output**: All visualizations, models, comprehensive insights

### Path 2: Quick Training (train_model.py)
```
Start â†’ Load Data â†’ Engineer Features â†’
Train Best Models â†’ Evaluate â†’ Save Best Model â†’ End
```
**Time**: 2-5 minutes  
**Output**: best_model.pkl, metrics summary

### Path 3: Prediction (predict.py)
```
Start â†’ Load Model â†’ Get Input â†’ Engineer Features â†’
Scale â†’ Predict â†’ Display Result â†’ End
```
**Time**: <1 second  
**Output**: Sales prediction

---

## ğŸ“ˆ Performance Optimization

### Data Processing
- **Vectorization**: Use pandas/numpy operations instead of loops
- **Memory**: Use appropriate data types (int32 vs int64)
- **Chunking**: Process large datasets in chunks if needed

### Model Training
- **Parallelization**: Use n_jobs=-1 for tree-based models
- **Early Stopping**: Stop training when validation loss plateaus
- **Batch Size**: Optimize for GPU memory (64 is good default)

### Inference
- **Model Loading**: Load model once, reuse for multiple predictions
- **Batch Prediction**: Predict multiple samples at once
- **Feature Caching**: Cache store statistics for fast lookup

---

## ğŸ” Error Handling Flow

```
User Input
    â†“
Input Validation
    â”œâ”€ Valid â†’ Continue
    â””â”€ Invalid â†’ Error Message â†’ Retry
        â†“
Feature Engineering
    â”œâ”€ Success â†’ Continue
    â””â”€ Failure â†’ Log Error â†’ Graceful Degradation
        â†“
Model Loading
    â”œâ”€ Found â†’ Continue
    â””â”€ Not Found â†’ Error: Run training first
        â†“
Prediction
    â”œâ”€ Success â†’ Return Result
    â””â”€ Failure â†’ Log Error â†’ Return Error Message
```

---

## ğŸ§ª Testing Architecture

### Unit Tests (Recommended)
- Test data loading
- Test feature engineering functions
- Test model initialization
- Test prediction pipeline

### Integration Tests (Recommended)
- Test end-to-end training
- Test end-to-end prediction
- Test model saving/loading

### Performance Tests (Recommended)
- Benchmark training time
- Benchmark prediction latency
- Monitor memory usage

---

## ğŸ“¦ Deployment Architecture (Future)

### Production Ready Components
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Web API (Flask/FastAPI)        â”‚
â”‚  â”œâ”€ /predict endpoint                  â”‚
â”‚  â”œâ”€ /batch-predict endpoint            â”‚
â”‚  â””â”€ /model-info endpoint               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Model  â”‚   â”‚ Feature â”‚
    â”‚ Server â”‚   â”‚ Store   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Monitoring &    â”‚
    â”‚  Logging         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Learning Path Through Codebase

**Beginner**: 
1. Start with QUICKSTART.md
2. Read README.md
3. Explore walmart.csv
4. Run predict.py with example

**Intermediate**:
1. Run train_model.py
2. Explore walmart_analysis.ipynb (EDA sections)
3. Understand feature engineering
4. Read INSIGHTS.md

**Advanced**:
1. Deep dive into notebook (ML/DL sections)
2. Experiment with hyperparameters
3. Add new models
4. Optimize performance
5. Deploy to production

---

**Last Updated**: 2025  
**Version**: 1.0

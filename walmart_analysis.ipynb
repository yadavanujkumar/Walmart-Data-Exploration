{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walmart Sales Data - Comprehensive Analysis\n",
    "## EDA, AI, ML, and Deep Learning\n",
    "\n",
    "This notebook performs comprehensive analysis of Walmart sales data including:\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Traditional Machine Learning Models\n",
    "- Deep Learning Models for Time Series Prediction\n",
    "- Feature Engineering and Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('walmart.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\"*50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Duplicate Rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"=\"*50)\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to datetime and extract features\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Week'] = df['Date'].dt.isocalendar().week\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['Quarter'] = df['Date'].dt.quarter\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(['Store', 'Date']).reset_index(drop=True)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(\"\\nNew columns added:\", ['Year', 'Month', 'Week', 'Day', 'DayOfWeek', 'Quarter'])\n",
    "print(\"\\nDataset shape after feature engineering:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for time series\n",
    "for lag in [1, 2, 3, 4]:\n",
    "    df[f'Sales_Lag_{lag}'] = df.groupby('Store')['Weekly_Sales'].shift(lag)\n",
    "\n",
    "# Rolling statistics\n",
    "df['Sales_Rolling_Mean_4'] = df.groupby('Store')['Weekly_Sales'].transform(lambda x: x.rolling(4, min_periods=1).mean())\n",
    "df['Sales_Rolling_Std_4'] = df.groupby('Store')['Weekly_Sales'].transform(lambda x: x.rolling(4, min_periods=1).std())\n",
    "\n",
    "# Store statistics\n",
    "store_stats = df.groupby('Store')['Weekly_Sales'].agg(['mean', 'std']).reset_index()\n",
    "store_stats.columns = ['Store', 'Store_Mean_Sales', 'Store_Std_Sales']\n",
    "df = df.merge(store_stats, on='Store', how='left')\n",
    "\n",
    "print(\"Time series features created!\")\n",
    "print(\"\\nNew features:\", [col for col in df.columns if 'Lag' in col or 'Rolling' in col or 'Store_' in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Weekly Sales\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(df['Weekly_Sales'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Weekly Sales', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Weekly Sales')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "axes[0, 1].boxplot(df['Weekly_Sales'])\n",
    "axes[0, 1].set_title('Box Plot of Weekly Sales', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Weekly Sales')\n",
    "\n",
    "# Sales by Holiday\n",
    "holiday_sales = df.groupby('Holiday_Flag')['Weekly_Sales'].mean()\n",
    "axes[1, 0].bar(['Non-Holiday', 'Holiday'], holiday_sales.values, color=['skyblue', 'coral'])\n",
    "axes[1, 0].set_title('Average Sales: Holiday vs Non-Holiday', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Average Weekly Sales')\n",
    "\n",
    "# Sales over time\n",
    "monthly_sales = df.groupby(df['Date'].dt.to_period('M'))['Weekly_Sales'].mean()\n",
    "axes[1, 1].plot(monthly_sales.index.astype(str), monthly_sales.values, marker='o', linewidth=2)\n",
    "axes[1, 1].set_title('Average Weekly Sales Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Average Weekly Sales')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].set_xticks(axes[1, 1].get_xticks()[::6])  # Show every 6th label\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage Sales on Holidays: ${holiday_sales[1]:,.2f}\")\n",
    "print(f\"Average Sales on Non-Holidays: ${holiday_sales[0]:,.2f}\")\n",
    "print(f\"Percentage Increase on Holidays: {((holiday_sales[1]/holiday_sales[0])-1)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Select numeric columns for correlation\n",
    "numeric_cols = ['Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price', \n",
    "                'CPI', 'Unemployment', 'Month', 'Quarter']\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation with Weekly Sales:\")\n",
    "print(\"=\"*50)\n",
    "print(correlation_matrix['Weekly_Sales'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store-wise analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Average sales by store\n",
    "store_avg_sales = df.groupby('Store')['Weekly_Sales'].mean().sort_values(ascending=False)\n",
    "axes[0, 0].bar(range(len(store_avg_sales)), store_avg_sales.values, color='steelblue')\n",
    "axes[0, 0].set_title('Average Weekly Sales by Store', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Store (sorted by sales)')\n",
    "axes[0, 0].set_ylabel('Average Weekly Sales')\n",
    "\n",
    "# Temperature vs Sales\n",
    "axes[0, 1].scatter(df['Temperature'], df['Weekly_Sales'], alpha=0.3, s=10)\n",
    "axes[0, 1].set_title('Temperature vs Weekly Sales', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Temperature')\n",
    "axes[0, 1].set_ylabel('Weekly Sales')\n",
    "\n",
    "# Fuel Price vs Sales\n",
    "axes[1, 0].scatter(df['Fuel_Price'], df['Weekly_Sales'], alpha=0.3, s=10, color='orange')\n",
    "axes[1, 0].set_title('Fuel Price vs Weekly Sales', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Fuel Price')\n",
    "axes[1, 0].set_ylabel('Weekly Sales')\n",
    "\n",
    "# Unemployment vs Sales\n",
    "axes[1, 1].scatter(df['Unemployment'], df['Weekly_Sales'], alpha=0.3, s=10, color='green')\n",
    "axes[1, 1].set_title('Unemployment vs Weekly Sales', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Unemployment Rate')\n",
    "axes[1, 1].set_ylabel('Weekly Sales')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_relationships.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 5 Stores by Average Sales:\")\n",
    "print(store_avg_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Monthly patterns\n",
    "monthly_avg = df.groupby('Month')['Weekly_Sales'].mean()\n",
    "axes[0].plot(monthly_avg.index, monthly_avg.values, marker='o', linewidth=2, markersize=8)\n",
    "axes[0].set_title('Average Sales by Month', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Average Weekly Sales')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Quarterly patterns\n",
    "quarterly_avg = df.groupby('Quarter')['Weekly_Sales'].mean()\n",
    "axes[1].bar(quarterly_avg.index, quarterly_avg.values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])\n",
    "axes[1].set_title('Average Sales by Quarter', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Quarter')\n",
    "axes[1].set_ylabel('Average Weekly Sales')\n",
    "\n",
    "# Day of week patterns\n",
    "dow_avg = df.groupby('DayOfWeek')['Weekly_Sales'].mean()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[2].bar(range(7), dow_avg.values, color='coral')\n",
    "axes[2].set_title('Average Sales by Day of Week', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Day of Week')\n",
    "axes[2].set_ylabel('Average Weekly Sales')\n",
    "axes[2].set_xticks(range(7))\n",
    "axes[2].set_xticklabels(day_names)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('seasonal_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN values (from lag features)\n",
    "df_ml = df.dropna().copy()\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = ['Store', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
    "                'Year', 'Month', 'Week', 'Quarter', 'DayOfWeek',\n",
    "                'Sales_Lag_1', 'Sales_Lag_2', 'Sales_Lag_3', 'Sales_Lag_4',\n",
    "                'Sales_Rolling_Mean_4', 'Sales_Rolling_Std_4',\n",
    "                'Store_Mean_Sales', 'Store_Std_Sales']\n",
    "\n",
    "X = df_ml[feature_cols]\n",
    "y = df_ml['Weekly_Sales']\n",
    "\n",
    "# Split data chronologically (80-20 split)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nFeatures used: {len(feature_cols)}\")\n",
    "print(f\"Feature names: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    results = {\n",
    "        'Model': name,\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'Predictions': y_test_pred\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Model evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=10),\n",
    "    'Lasso Regression': Lasso(alpha=100),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    results = evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    results_list.append(results)\n",
    "    print(f\"  Train R²: {results['Train R²']:.4f}, Test R²: {results['Test R²']:.4f}\")\n",
    "    print(f\"  Test RMSE: ${results['Test RMSE']:,.2f}\\n\")\n",
    "\n",
    "print(\"All models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "results_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Predictions'} for r in results_list])\n",
    "results_df = results_df.sort_values('Test R²', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# R² comparison\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[0].bar(x - width/2, results_df['Train R²'], width, label='Train R²', alpha=0.8)\n",
    "axes[0].bar(x + width/2, results_df['Test R²'], width, label='Test R²', alpha=0.8)\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('R² Score')\n",
    "axes[0].set_title('R² Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[1].bar(x - width/2, results_df['Train RMSE'], width, label='Train RMSE', alpha=0.8)\n",
    "axes[1].bar(x + width/2, results_df['Test RMSE'], width, label='Test RMSE', alpha=0.8)\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "rf_model = models['Random Forest']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(feature_importance)), feature_importance['Importance'])\n",
    "plt.yticks(range(len(feature_importance)), feature_importance['Feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions vs Actual for best model\n",
    "best_model_idx = results_df['Test R²'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "best_predictions = results_list[best_model_idx]['Predictions']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(y_test)), y_test.values, label='Actual', alpha=0.7, linewidth=2)\n",
    "plt.plot(range(len(y_test)), best_predictions, label='Predicted', alpha=0.7, linewidth=2)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Weekly Sales')\n",
    "plt.title(f'Actual vs Predicted Sales - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions_vs_actual.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test R² Score: {results_df.loc[best_model_idx, 'Test R²']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "def create_nn_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "nn_model = create_nn_model(X_train_scaled.shape[1])\n",
    "\n",
    "print(\"Neural Network Architecture:\")\n",
    "print(\"=\"*50)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Neural Network...\\n\")\n",
    "history = nn_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nNeural Network training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Neural Network\n",
    "nn_train_pred = nn_model.predict(X_train_scaled, verbose=0).flatten()\n",
    "nn_test_pred = nn_model.predict(X_test_scaled, verbose=0).flatten()\n",
    "\n",
    "nn_train_r2 = r2_score(y_train, nn_train_pred)\n",
    "nn_test_r2 = r2_score(y_test, nn_test_pred)\n",
    "nn_train_rmse = np.sqrt(mean_squared_error(y_train, nn_train_pred))\n",
    "nn_test_rmse = np.sqrt(mean_squared_error(y_test, nn_test_pred))\n",
    "nn_train_mae = mean_absolute_error(y_train, nn_train_pred)\n",
    "nn_test_mae = mean_absolute_error(y_test, nn_test_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NEURAL NETWORK RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Train R²: {nn_train_r2:.4f}\")\n",
    "print(f\"Test R²: {nn_test_r2:.4f}\")\n",
    "print(f\"Train RMSE: ${nn_train_rmse:,.2f}\")\n",
    "print(f\"Test RMSE: ${nn_test_rmse:,.2f}\")\n",
    "print(f\"Train MAE: ${nn_train_mae:,.2f}\")\n",
    "print(f\"Test MAE: ${nn_test_mae:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Training and Validation MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "def create_sequences(data, target, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X_seq.append(data[i:i+seq_length])\n",
    "        y_seq.append(target[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 10\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train.values, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test.values, seq_length)\n",
    "\n",
    "print(f\"LSTM input shape: {X_train_seq.shape}\")\n",
    "print(f\"LSTM output shape: {y_train_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM Model\n",
    "def create_lstm_model(seq_length, n_features):\n",
    "    model = Sequential([\n",
    "        LSTM(128, activation='tanh', return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        LSTM(64, activation='tanh', return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        LSTM(32, activation='tanh'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "lstm_model = create_lstm_model(seq_length, X_train_scaled.shape[1])\n",
    "\n",
    "print(\"LSTM Architecture:\")\n",
    "print(\"=\"*50)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM\n",
    "print(\"Training LSTM Model...\\n\")\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nLSTM training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LSTM\n",
    "lstm_train_pred = lstm_model.predict(X_train_seq, verbose=0).flatten()\n",
    "lstm_test_pred = lstm_model.predict(X_test_seq, verbose=0).flatten()\n",
    "\n",
    "lstm_train_r2 = r2_score(y_train_seq, lstm_train_pred)\n",
    "lstm_test_r2 = r2_score(y_test_seq, lstm_test_pred)\n",
    "lstm_train_rmse = np.sqrt(mean_squared_error(y_train_seq, lstm_train_pred))\n",
    "lstm_test_rmse = np.sqrt(mean_squared_error(y_test_seq, lstm_test_pred))\n",
    "lstm_train_mae = mean_absolute_error(y_train_seq, lstm_train_pred)\n",
    "lstm_test_mae = mean_absolute_error(y_test_seq, lstm_test_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LSTM MODEL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Train R²: {lstm_train_r2:.4f}\")\n",
    "print(f\"Test R²: {lstm_test_r2:.4f}\")\n",
    "print(f\"Train RMSE: ${lstm_train_rmse:,.2f}\")\n",
    "print(f\"Test RMSE: ${lstm_test_rmse:,.2f}\")\n",
    "print(f\"Train MAE: ${lstm_train_mae:,.2f}\")\n",
    "print(f\"Test MAE: ${lstm_test_mae:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LSTM training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(lstm_history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(lstm_history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('LSTM Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(lstm_history.history['mae'], label='Train MAE', linewidth=2)\n",
    "axes[1].plot(lstm_history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('LSTM Training and Validation MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model Comparison and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models including deep learning\n",
    "all_models_results = pd.concat([\n",
    "    results_df[['Model', 'Test R²', 'Test RMSE', 'Test MAE']],\n",
    "    pd.DataFrame([{\n",
    "        'Model': 'Neural Network',\n",
    "        'Test R²': nn_test_r2,\n",
    "        'Test RMSE': nn_test_rmse,\n",
    "        'Test MAE': nn_test_mae\n",
    "    }, {\n",
    "        'Model': 'LSTM',\n",
    "        'Test R²': lstm_test_r2,\n",
    "        'Test RMSE': lstm_test_rmse,\n",
    "        'Test MAE': lstm_test_mae\n",
    "    }])\n",
    "]).sort_values('Test R²', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(all_models_results.to_string(index=False))\n",
    "\n",
    "# Visualize final comparison\n",
    "plt.figure(figsize=(14, 6))\n",
    "x = np.arange(len(all_models_results))\n",
    "plt.bar(x, all_models_results['Test R²'], color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Test R² Score', fontsize=12)\n",
    "plt.title('Final Model Comparison - Test R² Scores', fontsize=16, fontweight='bold')\n",
    "plt.xticks(x, all_models_results['Model'], rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(all_models_results['Test R²']):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis for best model\n",
    "best_overall_idx = all_models_results['Test R²'].idxmax()\n",
    "best_overall_model = all_models_results.loc[best_overall_idx, 'Model']\n",
    "\n",
    "if best_overall_model == 'Neural Network':\n",
    "    residuals = y_test.values - nn_test_pred\n",
    "elif best_overall_model == 'LSTM':\n",
    "    residuals = y_test_seq - lstm_test_pred\n",
    "else:\n",
    "    model_idx = results_df[results_df['Model'] == best_overall_model].index[0]\n",
    "    residuals = y_test.values - results_list[model_idx]['Predictions']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Residual plot\n",
    "axes[0].scatter(range(len(residuals)), residuals, alpha=0.5, s=20)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Sample Index')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].set_title(f'Residual Plot - {best_overall_model}', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Residuals')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Residual Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[2])\n",
    "axes[2].set_title('Q-Q Plot', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('residual_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nResidual Statistics for {best_overall_model}:\")\n",
    "print(f\"Mean: ${np.mean(residuals):,.2f}\")\n",
    "print(f\"Std: ${np.std(residuals):,.2f}\")\n",
    "print(f\"Min: ${np.min(residuals):,.2f}\")\n",
    "print(f\"Max: ${np.max(residuals):,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHTS FROM WALMART SALES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATA CHARACTERISTICS:\")\n",
    "print(f\"   - Dataset contains {len(df)} records across {df['Store'].nunique()} stores\")\n",
    "print(f\"   - Time period: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   - Average weekly sales: ${df['Weekly_Sales'].mean():,.2f}\")\n",
    "print(f\"   - Sales standard deviation: ${df['Weekly_Sales'].std():,.2f}\")\n",
    "\n",
    "print(\"\\n2. BUSINESS INSIGHTS:\")\n",
    "holiday_impact = ((df[df['Holiday_Flag']==1]['Weekly_Sales'].mean() / \n",
    "                   df[df['Holiday_Flag']==0]['Weekly_Sales'].mean()) - 1) * 100\n",
    "print(f\"   - Holiday weeks show {holiday_impact:.2f}% {'higher' if holiday_impact > 0 else 'lower'} sales\")\n",
    "print(f\"   - Best performing quarter: Q{quarterly_avg.idxmax()} with ${quarterly_avg.max():,.2f} avg sales\")\n",
    "print(f\"   - Worst performing quarter: Q{quarterly_avg.idxmin()} with ${quarterly_avg.min():,.2f} avg sales\")\n",
    "\n",
    "print(\"\\n3. CORRELATION INSIGHTS:\")\n",
    "top_correlations = correlation_matrix['Weekly_Sales'].drop('Weekly_Sales').abs().sort_values(ascending=False)\n",
    "print(f\"   - Strongest predictor: {top_correlations.index[0]} (correlation: {top_correlations.values[0]:.4f})\")\n",
    "print(f\"   - Temperature shows {'positive' if correlation_matrix.loc['Temperature', 'Weekly_Sales'] > 0 else 'negative'} correlation with sales\")\n",
    "print(f\"   - Unemployment shows {'positive' if correlation_matrix.loc['Unemployment', 'Weekly_Sales'] > 0 else 'negative'} correlation with sales\")\n",
    "\n",
    "print(\"\\n4. MODEL PERFORMANCE:\")\n",
    "best_r2 = all_models_results['Test R²'].max()\n",
    "best_model_name = all_models_results.loc[all_models_results['Test R²'].idxmax(), 'Model']\n",
    "best_rmse = all_models_results.loc[all_models_results['Test R²'].idxmax(), 'Test RMSE']\n",
    "print(f\"   - Best performing model: {best_model_name}\")\n",
    "print(f\"   - Best R² score: {best_r2:.4f} (explains {best_r2*100:.2f}% of variance)\")\n",
    "print(f\"   - Best RMSE: ${best_rmse:,.2f}\")\n",
    "print(f\"   - Average prediction error: {(best_rmse/df['Weekly_Sales'].mean())*100:.2f}% of mean sales\")\n",
    "\n",
    "print(\"\\n5. FEATURE IMPORTANCE:\")\n",
    "print(f\"   - Top 3 features: {', '.join(feature_importance.head(3)['Feature'].tolist())}\")\n",
    "\n",
    "print(\"\\n6. RECOMMENDATIONS:\")\n",
    "print(\"   - Focus inventory and staffing on high-performing stores\")\n",
    "print(\"   - Prepare for seasonal variations, especially Q4 peaks\")\n",
    "if holiday_impact > 0:\n",
    "    print(\"   - Increase inventory and promotions during holiday weeks\")\n",
    "print(\"   - Monitor unemployment and CPI as economic indicators for sales forecasting\")\n",
    "print(f\"   - Use {best_model_name} for accurate sales predictions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "import joblib\n",
    "\n",
    "# Save best traditional ML model\n",
    "best_trad_model = models[results_df.iloc[0]['Model']]\n",
    "joblib.dump(best_trad_model, 'best_traditional_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Save deep learning models\n",
    "nn_model.save('neural_network_model.h5')\n",
    "lstm_model.save('lstm_model.h5')\n",
    "\n",
    "print(\"\\nModels saved successfully!\")\n",
    "print(\"Files created:\")\n",
    "print(\"  - best_traditional_model.pkl\")\n",
    "print(\"  - scaler.pkl\")\n",
    "print(\"  - neural_network_model.h5\")\n",
    "print(\"  - lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This comprehensive analysis of Walmart sales data includes:\n",
    "\n",
    "### 1. Exploratory Data Analysis (EDA)\n",
    "- Statistical summaries and distributions\n",
    "- Correlation analysis\n",
    "- Time series patterns and seasonality\n",
    "- Store-wise performance analysis\n",
    "\n",
    "### 2. Traditional Machine Learning Models\n",
    "- Linear Regression (baseline)\n",
    "- Ridge and Lasso Regression (regularized)\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "\n",
    "### 3. Deep Learning Models\n",
    "- Deep Neural Network with dropout and batch normalization\n",
    "- LSTM for time series prediction\n",
    "\n",
    "### 4. Feature Engineering\n",
    "- Temporal features (year, month, week, quarter)\n",
    "- Lag features for time series\n",
    "- Rolling statistics\n",
    "- Store-level aggregations\n",
    "\n",
    "### 5. Model Evaluation\n",
    "- R² score for variance explained\n",
    "- RMSE for prediction accuracy\n",
    "- MAE for average error\n",
    "- Residual analysis\n",
    "\n",
    "The analysis provides actionable insights for business decision-making and accurate sales forecasting capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
